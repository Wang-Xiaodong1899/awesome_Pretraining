# awesome_Pretraining

## Visual-pretraining
### 2021.12
1. **MaskFeat**: Wei, Chen, Haoqi Fan, Saining Xie, Chao-Yuan Wu, Alan Yuille, and Christoph Feichtenhofer. "Masked Feature Prediction for Self-Supervised Visual Pre-Training." [[Paper](https://arxiv.org/pdf/2112.09133.pdf)]. Note: **Partially exceeds MAE**(Kaiming He).
2. **MViT**: Li, Yanghao, Chao-Yuan Wu, Haoqi Fan, Karttikeya Mangalam, Bo Xiong, Jitendra Malik, and Christoph Feichtenhofer. "Improved Multiscale Vision Transformers for Classification and Detection." [[Paper](https://arxiv.org/pdf/2112.01526.pdf)]. Note: **SOTA in 3 domains** (88.8% accuracy on ImageNet classification, 56.1 AP^box on COCO object detection, 86.1% on Kinetics-400).

### 2021.11
1. **MAE**: He, Kaiming, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll√°r, and Ross Girshick. "Masked autoencoders are scalable vision learners." [[Paper](https://arxiv.org/pdf/2111.06377.pdf)].
## Language-Image Pretraining
### 2021.12
1. **RegionCLIP**: Zhong, Yiwu, Jianwei Yang, Pengchuan Zhang, Chunyuan Li, Noel Codella, Liunian Harold Li, Luowei Zhou et al. "RegionCLIP: Region-based Language-Image Pretraining." [[Paper](https://arxiv.org/pdf/2112.09106.pdf)]. Note: **Exceeds CLIP**(OpenAI).
